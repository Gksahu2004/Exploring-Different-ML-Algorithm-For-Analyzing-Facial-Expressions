{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb6c958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: processed_faces_newFinal/encoded_landmarks_with_va_geometric.csv\n",
      "DataFrame head (first 5 rows with new features):\n",
      "  emotion  landmark_0_x  landmark_0_y  landmark_1_x  landmark_1_y  \\\n",
      "0   anger            61           258            64           319   \n",
      "1   anger            56           264            60           325   \n",
      "2   anger            67           258            69           318   \n",
      "3   anger             3           227            11           295   \n",
      "4   anger             7           227            16           293   \n",
      "\n",
      "   landmark_2_x  landmark_2_y  landmark_3_x  landmark_3_y  landmark_4_x  ...  \\\n",
      "0            70           375            83           428           104  ...   \n",
      "1            66           382            80           436           103  ...   \n",
      "2            75           374            87           428           108  ...   \n",
      "3            25           359            42           421            67  ...   \n",
      "4            29           356            46           418            68  ...   \n",
      "\n",
      "   norm_right_eyebrow_eye_dist  left_eye_area  right_eye_area  mouth_area  \\\n",
      "0                     0.353252         1418.5          1451.0        72.5   \n",
      "1                     0.361663         1452.0          1470.0        91.0   \n",
      "2                     0.360687         1258.0          1262.5       127.0   \n",
      "3                     0.317803         1890.5          1859.0       399.5   \n",
      "4                     0.315189         1835.5          1823.5       366.5   \n",
      "\n",
      "   left_eyebrow_raise  right_eyebrow_raise  mouth_height_width_ratio  valence  \\\n",
      "0           25.773048            30.220026                  0.007806     -0.5   \n",
      "1           26.248809            29.094673                  0.007893     -0.5   \n",
      "2           25.932605            28.783676                  0.011167     -0.5   \n",
      "3           21.982948            24.748737                  0.017861     -0.5   \n",
      "4           22.610838            24.186773                  0.016942     -0.5   \n",
      "\n",
      "   arousal  emotion_encoded  \n",
      "0      0.8                0  \n",
      "1      0.8                0  \n",
      "2      0.8                0  \n",
      "3      0.8                0  \n",
      "4      0.8                0  \n",
      "\n",
      "[5 rows x 161 columns]\n",
      "\n",
      "DataFrame columns (expecting raw landmarks, geometric, valence, arousal, emotion_encoded):\n",
      "['emotion', 'landmark_0_x', 'landmark_0_y', 'landmark_1_x', 'landmark_1_y', 'landmark_2_x', 'landmark_2_y', 'landmark_3_x', 'landmark_3_y', 'landmark_4_x', 'landmark_4_y', 'landmark_5_x', 'landmark_5_y', 'landmark_6_x', 'landmark_6_y', 'landmark_7_x', 'landmark_7_y', 'landmark_8_x', 'landmark_8_y', 'landmark_9_x', 'landmark_9_y', 'landmark_10_x', 'landmark_10_y', 'landmark_11_x', 'landmark_11_y', 'landmark_12_x', 'landmark_12_y', 'landmark_13_x', 'landmark_13_y', 'landmark_14_x', 'landmark_14_y', 'landmark_15_x', 'landmark_15_y', 'landmark_16_x', 'landmark_16_y', 'landmark_17_x', 'landmark_17_y', 'landmark_18_x', 'landmark_18_y', 'landmark_19_x', 'landmark_19_y', 'landmark_20_x', 'landmark_20_y', 'landmark_21_x', 'landmark_21_y', 'landmark_22_x', 'landmark_22_y', 'landmark_23_x', 'landmark_23_y', 'landmark_24_x', 'landmark_24_y', 'landmark_25_x', 'landmark_25_y', 'landmark_26_x', 'landmark_26_y', 'landmark_27_x', 'landmark_27_y', 'landmark_28_x', 'landmark_28_y', 'landmark_29_x', 'landmark_29_y', 'landmark_30_x', 'landmark_30_y', 'landmark_31_x', 'landmark_31_y', 'landmark_32_x', 'landmark_32_y', 'landmark_33_x', 'landmark_33_y', 'landmark_34_x', 'landmark_34_y', 'landmark_35_x', 'landmark_35_y', 'landmark_36_x', 'landmark_36_y', 'landmark_37_x', 'landmark_37_y', 'landmark_38_x', 'landmark_38_y', 'landmark_39_x', 'landmark_39_y', 'landmark_40_x', 'landmark_40_y', 'landmark_41_x', 'landmark_41_y', 'landmark_42_x', 'landmark_42_y', 'landmark_43_x', 'landmark_43_y', 'landmark_44_x', 'landmark_44_y', 'landmark_45_x', 'landmark_45_y', 'landmark_46_x', 'landmark_46_y', 'landmark_47_x', 'landmark_47_y', 'landmark_48_x', 'landmark_48_y', 'landmark_49_x', 'landmark_49_y', 'landmark_50_x', 'landmark_50_y', 'landmark_51_x', 'landmark_51_y', 'landmark_52_x', 'landmark_52_y', 'landmark_53_x', 'landmark_53_y', 'landmark_54_x', 'landmark_54_y', 'landmark_55_x', 'landmark_55_y', 'landmark_56_x', 'landmark_56_y', 'landmark_57_x', 'landmark_57_y', 'landmark_58_x', 'landmark_58_y', 'landmark_59_x', 'landmark_59_y', 'landmark_60_x', 'landmark_60_y', 'landmark_61_x', 'landmark_61_y', 'landmark_62_x', 'landmark_62_y', 'landmark_63_x', 'landmark_63_y', 'landmark_64_x', 'landmark_64_y', 'landmark_65_x', 'landmark_65_y', 'landmark_66_x', 'landmark_66_y', 'landmark_67_x', 'landmark_67_y', 'left_ear', 'right_ear', 'avg_ear', 'mar', 'left_eyebrow_eye_dist', 'right_eyebrow_eye_dist', 'nose_chin_vertical_dist', 'mouth_width', 'nose_width', 'inter_ocular_dist', 'norm_nose_chin_vertical_dist', 'norm_mouth_width', 'norm_nose_width', 'norm_left_eyebrow_eye_dist', 'norm_right_eyebrow_eye_dist', 'left_eye_area', 'right_eye_area', 'mouth_area', 'left_eyebrow_raise', 'right_eyebrow_raise', 'mouth_height_width_ratio', 'valence', 'arousal', 'emotion_encoded']\n",
      "\n",
      "Features (X) shape: (980, 159)\n",
      "Target (y) shape: (980,)\n",
      "\n",
      "Data split successfully!\n",
      "X_train shape (training features): (784, 159)\n",
      "X_test shape (testing features): (196, 159)\n",
      "y_train shape (training labels): (784,)\n",
      "y_test shape (testing labels): (196,)\n",
      "\n",
      "✅ Split datasets (with geometric features) saved to processed_faces_newFinal/\n",
      "   as X_train_geometric.joblib, X_test_geometric.joblib, y_train_geometric.joblib, y_test_geometric.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib \n",
    "import os \n",
    "\n",
    "# Define the path to your new encoded CSV file which includes geometric features and V-A\n",
    "encoded_csv_path = 'processed_faces_newFinal/encoded_landmarks_with_va_geometric.csv'\n",
    "output_dir = 'processed_faces_newFinal' # Define output directory for split data\n",
    "\n",
    "try:\n",
    "    # Load the encoded data\n",
    "    df_encoded = pd.read_csv(encoded_csv_path)\n",
    "    print(f\"Successfully loaded data from: {encoded_csv_path}\")\n",
    "    print(\"DataFrame head (first 5 rows with new features):\")\n",
    "    print(df_encoded.head())\n",
    "    print(f\"\\nDataFrame columns (expecting raw landmarks, geometric, valence, arousal, emotion_encoded):\")\n",
    "    print(df_encoded.columns.tolist())\n",
    "\n",
    "\n",
    "    # Separate features (X) and target (y)\n",
    "    # X will contain all landmark coordinates, geometric features, valence, and arousal\n",
    "    # y will contain the encoded 'emotion' label\n",
    "    # We drop 'emotion' (original text label) to prevent data leakage and use emotion_encoded\n",
    "    X = df_encoded.drop(['emotion', 'emotion_encoded'], axis=1) # Drop original emotion and the encoded target\n",
    "    y = df_encoded['emotion_encoded']              # Select emotion_encoded as the target\n",
    "\n",
    "    print(f\"\\nFeatures (X) shape: {X.shape}\")\n",
    "    print(f\"Target (y) shape: {y.shape}\")\n",
    "\n",
    "    # Perform the train-test split\n",
    "    # test_size=0.20 means 20% of the data will be used for testing, 80% for training\n",
    "    # random_state ensures reproducibility of the split\n",
    "    # stratify=y ensures that the proportion of each emotion class is the same in both sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify=y)\n",
    "\n",
    "    print(\"\\nData split successfully!\")\n",
    "    print(f\"X_train shape (training features): {X_train.shape}\")\n",
    "    print(f\"X_test shape (testing features): {X_test.shape}\")\n",
    "    print(f\"y_train shape (training labels): {y_train.shape}\")\n",
    "    print(f\"y_test shape (testing labels): {y_test.shape}\")\n",
    "\n",
    "    # --- Save the split datasets ---\n",
    "    # Using joblib.dump is efficient for saving large arrays/DataFrames\n",
    "    joblib.dump(X_train, os.path.join(output_dir, 'X_train_geometric.joblib')) # New filename\n",
    "    joblib.dump(X_test, os.path.join(output_dir, 'X_test_geometric.joblib'))   # New filename\n",
    "    joblib.dump(y_train, os.path.join(output_dir, 'y_train_geometric.joblib')) # New filename\n",
    "    joblib.dump(y_test, os.path.join(output_dir, 'y_test_geometric.joblib'))   # New filename\n",
    "    \n",
    "    print(f\"\\n✅ Split datasets (with geometric features) saved to {output_dir}/\")\n",
    "    print(f\"   as X_train_geometric.joblib, X_test_geometric.joblib, y_train_geometric.joblib, y_test_geometric.joblib\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{encoded_csv_path}' was not found.\")\n",
    "    print(\"Please ensure 'process_emotions.py' completed successfully and the CSV file exists at the specified path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae831a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
