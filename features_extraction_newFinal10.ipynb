{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a07b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversion complete. All .pgm images saved as .png in 'atnt_images' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# INPUT folder containing s1 to s40 folders\n",
    "input_root = 'archive_5'       # <- change this to your folder name (e.g., 'att_faces')\n",
    "output_root = 'atnt_images'               # <- folder to save PNGs (will be created)\n",
    "\n",
    "# Choose output image format\n",
    "output_format = 'png'  # change to 'jpg' if you prefer JPEG\n",
    "\n",
    "# Create output root directory if it doesn't exist\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "# Traverse subject folders\n",
    "for subject in sorted(os.listdir(input_root)):\n",
    "    subject_path = os.path.join(input_root, subject)\n",
    "    \n",
    "    if os.path.isdir(subject_path):\n",
    "        output_subject_path = os.path.join(output_root, subject)\n",
    "        os.makedirs(output_subject_path, exist_ok=True)\n",
    "\n",
    "        # Traverse each .pgm file inside subject folder\n",
    "        for file in sorted(os.listdir(subject_path)):\n",
    "            if file.endswith('.pgm'):\n",
    "                pgm_file_path = os.path.join(subject_path, file)\n",
    "                image = cv2.imread(pgm_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "                # Create output filename\n",
    "                filename_wo_ext = os.path.splitext(file)[0]\n",
    "                output_file_path = os.path.join(output_subject_path, f\"{filename_wo_ext}.{output_format}\")\n",
    "\n",
    "                # Save as PNG or JPG\n",
    "                cv2.imwrite(output_file_path, image)\n",
    "\n",
    "print(f\"✅ Conversion complete. All .pgm images saved as .{output_format} in '{output_root}' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108a7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting AT&T face dataset processing...\n",
      "\n",
      "Processing: s1\n",
      "\n",
      "Processing: s10\n",
      "\n",
      "Processing: s11\n",
      "\n",
      "Processing: s12\n",
      "\n",
      "Processing: s13\n",
      "\n",
      "Processing: s14\n",
      "\n",
      "Processing: s15\n",
      "\n",
      "Processing: s16\n",
      "\n",
      "Processing: s17\n",
      "\n",
      "Processing: s18\n",
      "\n",
      "Processing: s19\n",
      "\n",
      "Processing: s2\n",
      "\n",
      "Processing: s20\n",
      "\n",
      "Processing: s21\n",
      "\n",
      "Processing: s22\n",
      "\n",
      "Processing: s23\n",
      "\n",
      "Processing: s24\n",
      "\n",
      "Processing: s25\n",
      "\n",
      "Processing: s26\n",
      "\n",
      "Processing: s27\n",
      "\n",
      "Processing: s28\n",
      "\n",
      "Processing: s29\n",
      "\n",
      "Processing: s3\n",
      "\n",
      "Processing: s30\n",
      "\n",
      "Processing: s31\n",
      "\n",
      "Processing: s32\n",
      "\n",
      "Processing: s33\n",
      "  No face found in 10.png\n",
      "  No face found in 4.png\n",
      "  No face found in 8.png\n",
      "\n",
      "Processing: s34\n",
      "\n",
      "Processing: s35\n",
      "  No face found in 2.png\n",
      "\n",
      "Processing: s36\n",
      "\n",
      "Processing: s37\n",
      "\n",
      "Processing: s38\n",
      "\n",
      "Processing: s39\n",
      "\n",
      "Processing: s4\n",
      "\n",
      "Processing: s40\n",
      "\n",
      "Processing: s5\n",
      "\n",
      "Processing: s6\n",
      "\n",
      "Processing: s7\n",
      "\n",
      "Processing: s8\n",
      "\n",
      "Processing: s9\n",
      "\n",
      "✅ Facial feature data saved to: processed_faces_newFinal10\\facial_features_and_landmarks_data.csv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "890804df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting facial landmark detection, shape drawing, and feature extraction (Stage 1)...\n",
      "\n",
      "Processing subject: s1...\n",
      "\n",
      "Processing subject: s2...\n",
      "\n",
      "Processing subject: s3...\n",
      "\n",
      "Processing subject: s4...\n",
      "\n",
      "Processing subject: s5...\n",
      "\n",
      "Processing subject: s6...\n",
      "\n",
      "Processing subject: s7...\n",
      "\n",
      "Processing subject: s8...\n",
      "\n",
      "Processing subject: s9...\n",
      "\n",
      "Processing subject: s10...\n",
      "\n",
      "Processing subject: s11...\n",
      "\n",
      "Processing subject: s12...\n",
      "\n",
      "Processing subject: s13...\n",
      "\n",
      "Processing subject: s14...\n",
      "\n",
      "Processing subject: s15...\n",
      "\n",
      "Processing subject: s16...\n",
      "\n",
      "Processing subject: s17...\n",
      "\n",
      "Processing subject: s18...\n",
      "\n",
      "Processing subject: s19...\n",
      "\n",
      "Processing subject: s20...\n",
      "\n",
      "Processing subject: s21...\n",
      "\n",
      "Processing subject: s22...\n",
      "\n",
      "Processing subject: s23...\n",
      "\n",
      "Processing subject: s24...\n",
      "\n",
      "Processing subject: s25...\n",
      "\n",
      "Processing subject: s26...\n",
      "\n",
      "Processing subject: s27...\n",
      "\n",
      "Processing subject: s28...\n",
      "\n",
      "Processing subject: s29...\n",
      "\n",
      "Processing subject: s30...\n",
      "\n",
      "Processing subject: s31...\n",
      "\n",
      "Processing subject: s32...\n",
      "\n",
      "Processing subject: s33...\n",
      "  No face detected in 10.png from s33 folder.\n",
      "  No face detected in 4.png from s33 folder.\n",
      "  No face detected in 8.png from s33 folder.\n",
      "\n",
      "Processing subject: s34...\n",
      "\n",
      "Processing subject: s35...\n",
      "  No face detected in 2.png from s35 folder.\n",
      "\n",
      "Processing subject: s36...\n",
      "\n",
      "Processing subject: s37...\n",
      "\n",
      "Processing subject: s38...\n",
      "\n",
      "Processing subject: s39...\n",
      "\n",
      "Processing subject: s40...\n",
      "\n",
      "Stage 1: Dlib processing, shape drawing, and initial feature extraction complete!\n",
      "All facial landmark coordinates and fitted shape parameters saved to: processed_faces_newFinal10\\facial_features_and_landmarks_data.csv\n",
      "\n",
      "Starting Stage 2: Eigenface Decomposition...\n",
      "Step 1: Collecting and preprocessing face images for PCA...\n",
      "Collected 396 images, each with 10000 pixels for PCA.\n",
      "Step 2: Calculating the mean face...\n",
      "Mean face saved to: processed_faces_newFinal10/eigenface_analysis_results\\mean_face.png\n",
      "Step 3: Centering the data (subtracting mean face)...\n",
      "Step 4 & 5: Computing eigenvectors and eigenvalues...\n",
      "Eigenvalues and eigenvectors computed.\n",
      "Step 6: Selecting top 50 Eigenfaces...\n",
      "Visualizing top Eigenfaces...\n",
      "Top Eigenfaces visualization saved to: processed_faces_newFinal10/eigenface_analysis_results\\top_eigenfaces.png\n",
      "Step 7: Projecting original faces onto Eigenface space...\n",
      "Projected 396 faces into a 50-dimensional Eigenface space.\n",
      "Step 8: Storing feature vectors in CSV...\n",
      "Eigenface feature vectors saved to: processed_faces_newFinal10/eigenface_analysis_results\\eigenface_features.csv\n",
      "Stage 2: Eigenface decomposition complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt # For Eigenface visualizations\n",
    "\n",
    "# --- GLOBAL CONFIGURATIONS ---\n",
    "# Load detector and predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\n",
    "    \"models/shape_predictor_68_face_landmarks.dat/shape_predictor_68_face_landmarks.dat\"\n",
    ")\n",
    "\n",
    "# Define the root directories for input and output\n",
    "root_input_dir = \"atnt_images\" # Changed to your new input directory\n",
    "root_output_dir = \"processed_faces_newFinal10\"\n",
    "\n",
    "# Define the scaling factor for upscaling images (for Dlib part)\n",
    "scale_factor = 12\n",
    "\n",
    "# List of subject folders (s1 to s40)\n",
    "subject_folders = [f\"s{i}\" for i in range(1, 41)] # Dynamically create s1, s2, ..., s40\n",
    "\n",
    "# Output directory for Eigenface related visualizations and data\n",
    "eigenface_output_dir = os.path.join(\"processed_faces_newFinal10/eigenface_analysis_results\")\n",
    "\n",
    "# Ensure all output root directories exist\n",
    "os.makedirs(root_output_dir, exist_ok=True)\n",
    "os.makedirs(eigenface_output_dir, exist_ok=True) # Create this now\n",
    "\n",
    "\n",
    "# --- Helper Function for Drawing Shapes ---\n",
    "def draw_facial_shapes(image, landmarks):\n",
    "    \"\"\"\n",
    "    Draws different geometric shapes on a given image based on facial landmarks.\n",
    "    Args:\n",
    "        image (numpy.ndarray): The image on which to draw.\n",
    "        landmarks (dlib.full_object_detection): Dlib's landmark object.\n",
    "    Returns:\n",
    "        numpy.ndarray: The image with shapes drawn.\n",
    "    \"\"\"\n",
    "    drawn_image = image.copy()\n",
    "\n",
    "    color_eyebrows = (0, 255, 0)\n",
    "    color_eyes = (255, 0, 0)\n",
    "    color_nose_bridge = (0, 255, 255)\n",
    "    color_nose_tip = (255, 255, 0)\n",
    "    color_lips = (0, 165, 255)\n",
    "    color_cheeks = (128, 0, 128)\n",
    "    thickness = 2\n",
    "\n",
    "    # Eyebrows (polylines)\n",
    "    for i in range(17, 21):\n",
    "        pt1 = (landmarks.part(i).x, landmarks.part(i).y)\n",
    "        pt2 = (landmarks.part(i + 1).x, landmarks.part(i + 1).y)\n",
    "        cv2.line(drawn_image, pt1, pt2, color_eyebrows, thickness)\n",
    "    for i in range(22, 26):\n",
    "        pt1 = (landmarks.part(i).x, landmarks.part(i).y)\n",
    "        pt2 = (landmarks.part(i + 1).x, landmarks.part(i + 1).y)\n",
    "        cv2.line(drawn_image, pt1, pt2, color_eyebrows, thickness)\n",
    "\n",
    "    # Eyes (Ellipses)\n",
    "    left_eye_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)])\n",
    "    if len(left_eye_points) >= 5:\n",
    "        try:\n",
    "            (center_le, axes_le, angle_le) = cv2.fitEllipse(left_eye_points)\n",
    "            if axes_le[0] > 0 and axes_le[1] > 0:\n",
    "                cv2.ellipse(drawn_image, (int(center_le[0]), int(center_le[1])),\n",
    "                            (int(axes_le[0] / 2), int(axes_le[1] / 2)),\n",
    "                            angle_le, 0, 360, color_eyes, thickness)\n",
    "        except cv2.error: pass\n",
    "\n",
    "    right_eye_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)])\n",
    "    if len(right_eye_points) >= 5:\n",
    "        try:\n",
    "            (center_re, axes_re, angle_re) = cv2.fitEllipse(right_eye_points)\n",
    "            if axes_re[0] > 0 and axes_re[1] > 0:\n",
    "                cv2.ellipse(drawn_image, (int(center_re[0]), int(center_re[1])),\n",
    "                            (int(axes_re[0] / 2), int(axes_re[1] / 2)),\n",
    "                            angle_re, 0, 360, color_eyes, thickness)\n",
    "        except cv2.error: pass\n",
    "\n",
    "    # Nose Bridge (Trapezium)\n",
    "    nose_bridge_pts = np.array([\n",
    "        (landmarks.part(27).x, landmarks.part(27).y), (landmarks.part(28).x, landmarks.part(28).y),\n",
    "        (landmarks.part(29).x, landmarks.part(29).y), (landmarks.part(30).x, landmarks.part(30).y)\n",
    "    ], np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(drawn_image, [nose_bridge_pts], True, color_nose_bridge, thickness)\n",
    "\n",
    "    # Nose Tip (Triangle)\n",
    "    nose_tip_pts = np.array([\n",
    "        (landmarks.part(30).x, landmarks.part(30).y), (landmarks.part(31).x, landmarks.part(31).y),\n",
    "        (landmarks.part(35).x, landmarks.part(35).y)\n",
    "    ], np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(drawn_image, [nose_tip_pts], True, color_nose_tip, thickness)\n",
    "\n",
    "    # Lips (Outer Lip Ellipse)\n",
    "    outer_lip_points = np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(48, 60)])\n",
    "    if len(outer_lip_points) >= 5:\n",
    "        try:\n",
    "            (center_ol, axes_ol, angle_ol) = cv2.fitEllipse(outer_lip_points)\n",
    "            if axes_ol[0] > 0 and axes_ol[1] > 0:\n",
    "                cv2.ellipse(drawn_image, (int(center_ol[0]), int(center_ol[1])),\n",
    "                            (int(axes_ol[0] / 2), int(axes_ol[1] / 2)),\n",
    "                            angle_ol, 0, 360, color_lips, thickness)\n",
    "        except cv2.error: pass\n",
    "\n",
    "    # Cheeks (Broader Triangles)\n",
    "    left_cheek_pts = np.array([\n",
    "        (landmarks.part(36).x, landmarks.part(36).y), (landmarks.part(2).x, landmarks.part(2).y),\n",
    "        (landmarks.part(48).x, landmarks.part(48).y)\n",
    "    ], np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(drawn_image, [left_cheek_pts], True, color_cheeks, thickness)\n",
    "\n",
    "    right_cheek_pts = np.array([\n",
    "        (landmarks.part(45).x, landmarks.part(45).y), (landmarks.part(14).x, landmarks.part(14).y),\n",
    "        (landmarks.part(54).x, landmarks.part(54).y)\n",
    "    ], np.int32).reshape((-1, 1, 2))\n",
    "    cv2.polylines(drawn_image, [right_cheek_pts], True, color_cheeks, thickness)\n",
    "\n",
    "    return drawn_image\n",
    "\n",
    "# --- Helper Functions for Curve Fitting ---\n",
    "\n",
    "def fit_parabola_params(points):\n",
    "    if len(points) < 3: return np.nan, np.nan, np.nan\n",
    "    x_coords = np.array([p[0] for p in points])\n",
    "    y_coords = np.array([p[1] for p in points])\n",
    "    try:\n",
    "        with np.errstate(all='raise'):\n",
    "            coefficients = np.polyfit(x_coords, y_coords, 2)\n",
    "            return tuple(coefficients)\n",
    "    except Exception: return np.nan, np.nan, np.nan\n",
    "\n",
    "def fit_ellipse_params(points):\n",
    "    if len(points) < 5: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    points_np = np.array(points, dtype=np.int32)\n",
    "    try:\n",
    "        (center, axes, angle) = cv2.fitEllipse(points_np)\n",
    "        if axes[0] <= 0 or axes[1] <= 0: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "        return center[0], center[1], axes[0], axes[1], angle\n",
    "    except cv2.error: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    except Exception: return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "\n",
    "# --- Main Processing Loop for Dlib, Drawing, and Initial Feature Extraction ---\n",
    "print(\"Starting facial landmark detection, shape drawing, and feature extraction (Stage 1)...\")\n",
    "\n",
    "all_facial_features_data = []\n",
    "\n",
    "for subject_id in subject_folders: # Loop through s1, s2, ..., s40\n",
    "    input_subject_path = os.path.join(root_input_dir, subject_id)\n",
    "\n",
    "    # Output paths adjusted to the new structure (subject_id instead of emotion)\n",
    "    output_with_photo_path = os.path.join(root_output_dir, subject_id, f\"{subject_id}_with_photo\")\n",
    "    output_without_photo_path = os.path.join(root_output_dir, subject_id, f\"{subject_id}_without_photo\")\n",
    "    output_shapes_drawn_path = os.path.join(root_output_dir, subject_id, f\"{subject_id}_shapes_drawn\")\n",
    "\n",
    "    os.makedirs(output_with_photo_path, exist_ok=True)\n",
    "    os.makedirs(output_without_photo_path, exist_ok=True)\n",
    "    os.makedirs(output_shapes_drawn_path, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nProcessing subject: {subject_id}...\")\n",
    "\n",
    "    for filename in os.listdir(input_subject_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "            image_path = os.path.join(input_subject_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # print(f\"  Processing file: {filename}\") # Uncomment for more verbose output\n",
    "\n",
    "            upscaled_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "            gray = cv2.cvtColor(upscaled_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            faces = detector(gray)\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                face = faces[0]\n",
    "                landmarks = predictor(gray, face)\n",
    "\n",
    "                # Store 'subject_id' instead of 'emotion'\n",
    "                current_image_features = {'subject_id': subject_id, 'filename': filename}\n",
    "\n",
    "                # Collect raw landmark data\n",
    "                for n in range(68):\n",
    "                    x = landmarks.part(n).x\n",
    "                    y = landmarks.part(n).y\n",
    "                    current_image_features[f'landmark_{n}_x'] = x\n",
    "                    current_image_features[f'landmark_{n}_y'] = y\n",
    "\n",
    "                # Apply Curve Fitting Algorithms and Store Parameters\n",
    "                leb_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(17, 22)]\n",
    "                a_leb, b_leb, c_leb = fit_parabola_params(leb_points)\n",
    "                current_image_features['leb_parabola_a'] = a_leb\n",
    "                current_image_features['leb_parabola_b'] = b_leb\n",
    "                current_image_features['leb_parabola_c'] = c_leb\n",
    "\n",
    "                reb_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(22, 27)]\n",
    "                a_reb, b_reb, c_reb = fit_parabola_params(reb_points)\n",
    "                current_image_features['reb_parabola_a'] = a_reb\n",
    "                current_image_features['reb_parabola_b'] = b_reb\n",
    "                current_image_features['reb_parabola_c'] = c_reb\n",
    "\n",
    "                le_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]\n",
    "                cx_le, cy_le, maj_le, min_le, ang_le = fit_ellipse_params(le_points)\n",
    "                current_image_features['le_ellipse_center_x'] = cx_le; current_image_features['le_ellipse_center_y'] = cy_le\n",
    "                current_image_features['le_ellipse_major_axis'] = maj_le; current_image_features['le_ellipse_minor_axis'] = min_le\n",
    "                current_image_features['le_ellipse_angle'] = ang_le\n",
    "\n",
    "                re_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]\n",
    "                cx_re, cy_re, maj_re, min_re, ang_re = fit_ellipse_params(re_points)\n",
    "                current_image_features['re_ellipse_center_x'] = cx_re; current_image_features['re_ellipse_center_y'] = cy_re\n",
    "                current_image_features['re_ellipse_major_axis'] = maj_re; current_image_features['re_ellipse_minor_axis'] = min_re\n",
    "                current_image_features['re_ellipse_angle'] = ang_re\n",
    "\n",
    "                ol_points = [(landmarks.part(n).x, landmarks.part(n).y) for n in range(48, 60)]\n",
    "                cx_ol, cy_ol, maj_ol, min_ol, ang_ol = fit_ellipse_params(ol_points)\n",
    "                current_image_features['ol_ellipse_center_x'] = cx_ol; current_image_features['ol_ellipse_center_y'] = cy_ol\n",
    "                current_image_features['ol_ellipse_major_axis'] = maj_ol; current_image_features['ol_ellipse_minor_axis'] = min_ol\n",
    "                current_image_features['ol_ellipse_angle'] = ang_ol\n",
    "\n",
    "                # Nose Bridge (Trapezium - extract vertices)\n",
    "                current_image_features['nose_bridge_v1_x'] = landmarks.part(27).x; current_image_features['nose_bridge_v1_y'] = landmarks.part(27).y\n",
    "                current_image_features['nose_bridge_v2_x'] = landmarks.part(28).x; current_image_features['nose_bridge_v2_y'] = landmarks.part(28).y\n",
    "                current_image_features['nose_bridge_v3_x'] = landmarks.part(29).x; current_image_features['nose_bridge_v3_y'] = landmarks.part(29).y\n",
    "                current_image_features['nose_bridge_v4_x'] = landmarks.part(30).x; current_image_features['nose_bridge_v4_y'] = landmarks.part(30).y\n",
    "\n",
    "                # Nose Tip (Triangle - extract vertices)\n",
    "                current_image_features['nose_tip_v1_x'] = landmarks.part(30).x; current_image_features['nose_tip_v1_y'] = landmarks.part(30).y\n",
    "                current_image_features['nose_tip_v2_x'] = landmarks.part(31).x; current_image_features['nose_tip_v2_y'] = landmarks.part(31).y\n",
    "                current_image_features['nose_tip_v3_x'] = landmarks.part(35).x; current_image_features['nose_tip_v3_y'] = landmarks.part(35).y\n",
    "\n",
    "                # Left Cheek (Triangle - extract vertices)\n",
    "                current_image_features['left_cheek_v1_x'] = landmarks.part(36).x; current_image_features['left_cheek_v1_y'] = landmarks.part(36).y\n",
    "                current_image_features['left_cheek_v2_x'] = landmarks.part(2).x; current_image_features['left_cheek_v2_y'] = landmarks.part(2).y\n",
    "                current_image_features['left_cheek_v3_x'] = landmarks.part(48).x; current_image_features['left_cheek_v3_y'] = landmarks.part(48).y\n",
    "\n",
    "                # Right Cheek (Triangle - extract vertices)\n",
    "                current_image_features['right_cheek_v1_x'] = landmarks.part(45).x; current_image_features['right_cheek_v1_y'] = landmarks.part(45).y\n",
    "                current_image_features['right_cheek_v2_x'] = landmarks.part(14).x; current_image_features['right_cheek_v2_y'] = landmarks.part(14).y\n",
    "                current_image_features['right_cheek_v3_x'] = landmarks.part(54).x; current_image_features['right_cheek_v3_y'] = landmarks.part(54).y\n",
    "\n",
    "                all_facial_features_data.append(current_image_features)\n",
    "\n",
    "                # Visualizations\n",
    "                drawn_image_with_photo = upscaled_image.copy()\n",
    "                drawn_image_without_photo = np.zeros(upscaled_image.shape, dtype=np.uint8)\n",
    "                drawn_image_shapes_only = np.zeros(upscaled_image.shape, dtype=np.uint8)\n",
    "\n",
    "                # Draw quadrant lines\n",
    "                nose_x = landmarks.part(30).x; nose_y = landmarks.part(30).y\n",
    "                img_h, img_w = drawn_image_with_photo.shape[:2]\n",
    "                cv2.line(drawn_image_with_photo, (nose_x, 0), (nose_x, img_h), (0, 255, 0), 1)\n",
    "                cv2.line(drawn_image_with_photo, (0, nose_y), (img_w, nose_y), (0, 255, 0), 1)\n",
    "\n",
    "                # Draw landmarks and labels\n",
    "                drawn_index = 1; seen = set()\n",
    "                for n in range(68):\n",
    "                    x = landmarks.part(n).x; y = landmarks.part(n).y\n",
    "                    if (x, y) in seen: continue\n",
    "                    seen.add((x, y))\n",
    "                    circle_radius = 2; fill_type = -1\n",
    "                    offset_x, offset_y = -6, 10\n",
    "                    if n in [37, 38, 39, 43, 44, 45]: offset_y = -10\n",
    "                    elif n == 49: offset_x = -20; offset_y = 6\n",
    "                    elif n == 50: offset_x = 0; offset_y = -8\n",
    "                    elif n == 65: offset_x = -14; offset_y = 10\n",
    "                    elif 48 <= n <= 54: offset_y = -8\n",
    "                    elif 55 <= n <= 59: offset_y = 10\n",
    "                    elif 60 <= n <= 64: offset_y = -8\n",
    "                    elif 65 <= n <= 67: offset_y = 10\n",
    "\n",
    "                    cv2.circle(drawn_image_with_photo, (x, y), circle_radius, (0, 0, 255), fill_type)\n",
    "                    cv2.putText(drawn_image_with_photo, str(drawn_index), (x + offset_x, y + offset_y),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "                    cv2.circle(drawn_image_without_photo, (x, y), circle_radius, (255, 255, 255), fill_type)\n",
    "                    cv2.putText(drawn_image_without_photo, str(drawn_index), (x + offset_x, y + offset_y),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                    drawn_index += 1\n",
    "\n",
    "                drawn_image_shapes_only = draw_facial_shapes(drawn_image_shapes_only, landmarks)\n",
    "\n",
    "                output_image_path_with_photo = os.path.join(output_with_photo_path, filename)\n",
    "                cv2.imwrite(output_image_path_with_photo, drawn_image_with_photo)\n",
    "                output_image_path_without_photo = os.path.join(output_without_photo_path, filename)\n",
    "                cv2.imwrite(output_image_path_without_photo, drawn_image_without_photo)\n",
    "                output_image_path_shapes_drawn = os.path.join(output_shapes_drawn_path, filename)\n",
    "                cv2.imwrite(output_image_path_shapes_drawn, drawn_image_shapes_only)\n",
    "\n",
    "            else:\n",
    "                print(f\"  No face detected in {filename} from {subject_id} folder.\")\n",
    "\n",
    "print(\"\\nStage 1: Dlib processing, shape drawing, and initial feature extraction complete!\")\n",
    "\n",
    "# Save all collected facial feature data to a single CSV file\n",
    "if all_facial_features_data:\n",
    "    df = pd.DataFrame(all_facial_features_data)\n",
    "    df = df.reindex(columns=sorted(df.columns))\n",
    "    csv_output_path = os.path.join(root_output_dir, \"facial_features_and_landmarks_data.csv\")\n",
    "    df.to_csv(csv_output_path, index=False)\n",
    "    print(f\"All facial landmark coordinates and fitted shape parameters saved to: {csv_output_path}\")\n",
    "else:\n",
    "    print(\"No facial feature data was collected in Stage 1.\")\n",
    "\n",
    "\n",
    "# --- Configuration for Eigenface Decomposition ---\n",
    "# Define the target size for all face images (Width, Height)\n",
    "face_target_size = (100, 100)\n",
    "\n",
    "# Number of top Eigenfaces to retain\n",
    "num_eigenfaces_to_keep = 50\n",
    "\n",
    "# --- Step 1: Data Preparation for Eigenfaces ---\n",
    "print(\"\\nStarting Stage 2: Eigenface Decomposition...\")\n",
    "print(\"Step 1: Collecting and preprocessing face images for PCA...\")\n",
    "\n",
    "all_face_vectors = []\n",
    "image_metadata_pca = [] # Use a separate list for PCA metadata to avoid conflicts\n",
    "\n",
    "for subject_id in subject_folders: # Loop through s1, s2, ..., s40\n",
    "    # Read from the '_shapes_drawn' folder, as these are upscaled and have shapes,\n",
    "    # but more importantly, they are already resized consistently by the previous step's upscaling.\n",
    "    # For purest Eigenfaces, ideally these would be tight crops of the face only.\n",
    "    subject_dir = os.path.join(root_output_dir, subject_id, f\"{subject_id}_shapes_drawn\") # Adjusted path\n",
    "    if not os.path.exists(subject_dir):\n",
    "        print(f\"Warning: Directory '{subject_dir}' not found. Skipping {subject_id} for PCA.\")\n",
    "        continue\n",
    "\n",
    "    for filename in os.listdir(subject_dir):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "            image_path = os.path.join(subject_dir, filename)\n",
    "            img = cv2.imread(image_path)\n",
    "\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not read image {image_path}. Skipping for PCA.\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale\n",
    "            gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Resize to uniform size (ensure consistency, even if already done by upscaling in stage 1)\n",
    "            # This is important as Dlib's upscaling is a factor, not a fixed size.\n",
    "            resized_face = cv2.resize(gray_img, face_target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Flatten the 2D image into a 1D vector\n",
    "            flattened_face = resized_face.flatten()\n",
    "\n",
    "            all_face_vectors.append(flattened_face)\n",
    "            image_metadata_pca.append({'subject_id': subject_id, 'filename': filename}) # Store subject_id\n",
    "\n",
    "if not all_face_vectors:\n",
    "    print(\"No face images found or processed for Eigenface decomposition. Exiting.\")\n",
    "    # You might want to exit the entire notebook or just skip this section\n",
    "    # For a notebook, print and return might be more appropriate.\n",
    "    # return\n",
    "else: # Only proceed if there's data\n",
    "    X = np.array(all_face_vectors, dtype=np.float64)\n",
    "    num_images, num_pixels = X.shape\n",
    "    print(f\"Collected {num_images} images, each with {num_pixels} pixels for PCA.\")\n",
    "\n",
    "    # --- Step 2: Calculate the Mean Face ---\n",
    "    print(\"Step 2: Calculating the mean face...\")\n",
    "    mean_face_vector = np.mean(X, axis=0)\n",
    "    mean_face_image = mean_face_vector.reshape(face_target_size)\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(mean_face_image, cmap='gray')\n",
    "    plt.title(\"Mean Face\")\n",
    "    plt.axis('off')\n",
    "    mean_face_path = os.path.join(eigenface_output_dir, \"mean_face.png\")\n",
    "    plt.savefig(mean_face_path)\n",
    "    plt.close()\n",
    "    print(f\"Mean face saved to: {mean_face_path}\")\n",
    "\n",
    "    # --- Step 3: Subtract the Mean Face ---\n",
    "    print(\"Step 3: Centering the data (subtracting mean face)...\")\n",
    "    X_centered = X - mean_face_vector\n",
    "\n",
    "    # --- Step 4 & 5: Compute Eigenvalues and Eigenvectors ---\n",
    "    print(\"Step 4 & 5: Computing eigenvectors and eigenvalues...\")\n",
    "    S_matrix = X_centered @ X_centered.T # N x N scatter matrix\n",
    "    eigenvalues_small, eigenvectors_small = np.linalg.eigh(S_matrix)\n",
    "\n",
    "    sorted_indices = np.argsort(eigenvalues_small)[::-1]\n",
    "    eigenvalues_small = eigenvalues_small[sorted_indices]\n",
    "    eigenvectors_small = eigenvectors_small[:, sorted_indices]\n",
    "\n",
    "    eigenfaces_raw = X_centered.T @ eigenvectors_small\n",
    "    eigenfaces = eigenfaces_raw / np.linalg.norm(eigenfaces_raw, axis=0) # Normalize\n",
    "\n",
    "    print(\"Eigenvalues and eigenvectors computed.\")\n",
    "\n",
    "    # --- Step 6: Select Principal Components (Eigenfaces) ---\n",
    "    print(f\"Step 6: Selecting top {num_eigenfaces_to_keep} Eigenfaces...\")\n",
    "    selected_eigenfaces = eigenfaces[:, :num_eigenfaces_to_keep]\n",
    "    selected_eigenvalues = eigenvalues_small[:num_eigenfaces_to_keep]\n",
    "\n",
    "    print(\"Visualizing top Eigenfaces...\")\n",
    "    fig, axes = plt.subplots(1, min(num_eigenfaces_to_keep, 10), figsize=(20, 4))\n",
    "    for i, ax in enumerate(axes):\n",
    "        eigenface_img = selected_eigenfaces[:, i].reshape(face_target_size)\n",
    "        ax.imshow(eigenface_img, cmap='gray')\n",
    "        ax.set_title(f'Eigenface {i+1}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    eigenfaces_plot_path = os.path.join(eigenface_output_dir, \"top_eigenfaces.png\")\n",
    "    plt.savefig(eigenfaces_plot_path)\n",
    "    plt.close()\n",
    "    print(f\"Top Eigenfaces visualization saved to: {eigenfaces_plot_path}\")\n",
    "\n",
    "    # --- Step 7: Project Faces onto Eigenface Space ---\n",
    "    print(\"Step 7: Projecting original faces onto Eigenface space...\")\n",
    "    feature_vectors = X_centered @ selected_eigenfaces\n",
    "    print(f\"Projected {num_images} faces into a {num_eigenfaces_to_keep}-dimensional Eigenface space.\")\n",
    "\n",
    "    # --- Step 8: Store Eigenfaces and Feature Vectors ---\n",
    "    print(\"Step 8: Storing feature vectors in CSV...\")\n",
    "    df_features = pd.DataFrame(feature_vectors)\n",
    "    df_features.columns = [f'eigen_feature_{i}' for i in range(num_eigenfaces_to_keep)]\n",
    "    df_metadata = pd.DataFrame(image_metadata_pca) # Use the correct metadata list for PCA\n",
    "    final_df_pca = pd.concat([df_metadata, df_features], axis=1)\n",
    "\n",
    "    features_csv_path_pca = os.path.join(eigenface_output_dir, \"eigenface_features.csv\")\n",
    "    final_df_pca.to_csv(features_csv_path_pca, index=False)\n",
    "\n",
    "    print(f\"Eigenface feature vectors saved to: {features_csv_path_pca}\")\n",
    "    print(\"Stage 2: Eigenface decomposition complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88398cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
