{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e6594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing emotion: anger\n",
      "Processing emotion: contempt\n",
      "Processing emotion: disgust\n",
      "Processing emotion: happy\n",
      "Processing emotion: sadness\n",
      "Processing emotion: fear\n",
      "Processing emotion: surprise\n",
      "\n",
      "All emotion folders processed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Load detector and predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\n",
    "    \"models/shape_predictor_68_face_landmarks.dat/shape_predictor_68_face_landmarks.dat\"\n",
    ")\n",
    "\n",
    "# Define the root directory for your emotion folders\n",
    "root_input_dir = \"archive_3\"\n",
    "root_output_dir = \"processed_faces_new\"\n",
    "\n",
    "# Define the scaling factor for upscaling images\n",
    "scale_factor = 6\n",
    "\n",
    "# Create the root output directory if it doesn't exist\n",
    "os.makedirs(root_output_dir, exist_ok=True)\n",
    "\n",
    "# List of emotion folders (assuming these are the names of your subfolders)\n",
    "emotion_folders = [\"anger\", \"contempt\", \"disgust\", \"happy\", \"sadness\", \"fear\", \"surprise\"]\n",
    "\n",
    "for emotion in emotion_folders:\n",
    "    input_emotion_path = os.path.join(root_input_dir, emotion)\n",
    "    output_emotion_path = os.path.join(root_output_dir, emotion)\n",
    "\n",
    "    # Create output directory for the current emotion if it doesn't exist\n",
    "    os.makedirs(output_emotion_path, exist_ok=True)\n",
    "    print(f\"Processing emotion: {emotion}\")\n",
    "\n",
    "    # Iterate through each image in the emotion folder\n",
    "    for filename in os.listdir(input_emotion_path):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\")):\n",
    "            image_path = os.path.join(input_emotion_path, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Upscale the image\n",
    "            upscaled_image = cv2.resize(image, (0, 0), fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "            gray = cv2.cvtColor(upscaled_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces\n",
    "            faces = detector(gray)\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                # Process the first detected face (you can modify this if you need to process all faces)\n",
    "                face = faces[0]\n",
    "                landmarks = predictor(gray, face)\n",
    "\n",
    "                drawn_image = upscaled_image.copy() # Draw landmarks on a copy of the upscaled image\n",
    "\n",
    "                # Get position of landmark 31 (index 30 in 0-based indexing)\n",
    "                nose_x = landmarks.part(30).x\n",
    "                nose_y = landmarks.part(30).y\n",
    "\n",
    "                # Draw quadrant lines centered at landmark 31\n",
    "                img_h, img_w = drawn_image.shape[:2]\n",
    "                cv2.line(drawn_image, (nose_x, 0), (nose_x, img_h), (0, 255, 0), 1)\n",
    "                cv2.line(drawn_image, (0, nose_y), (img_w, nose_y), (0, 255, 0), 1)\n",
    "\n",
    "                drawn_index = 1\n",
    "                seen = set()\n",
    "\n",
    "                for n in range(68):\n",
    "                    x = landmarks.part(n).x\n",
    "                    y = landmarks.part(n).y\n",
    "\n",
    "                    if (x, y) in seen:\n",
    "                        continue\n",
    "                    seen.add((x, y))\n",
    "\n",
    "                    # Special highlight for landmark 31\n",
    "                    if n == 30:\n",
    "                        cv2.circle(drawn_image, (x, y), 5, (0, 0, 255), -1)\n",
    "                        cv2.putText(drawn_image, str(drawn_index), (x - 12, y - 12),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "                    else:\n",
    "                        # Draw standard landmark\n",
    "                        cv2.circle(drawn_image, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "                        # Offset for label\n",
    "                        offset_x, offset_y = -6, 10\n",
    "\n",
    "                        if n in [37, 38, 39, 43, 44, 45]:\n",
    "                            offset_y = -10\n",
    "                        elif n == 49:\n",
    "                            offset_x = -20\n",
    "                            offset_y = 6\n",
    "                        elif n == 50:\n",
    "                            offset_x = 0\n",
    "                            offset_y = -8\n",
    "                        elif n == 65:\n",
    "                            offset_x = -14\n",
    "                            offset_y = 10\n",
    "                        elif 48 <= n <= 54:\n",
    "                            offset_y = -8\n",
    "                        elif 55 <= n <= 59:\n",
    "                            offset_y = 10\n",
    "                        elif 60 <= n <= 64:\n",
    "                            offset_y = -8\n",
    "                        elif 65 <= n <= 67:\n",
    "                            offset_y = 10\n",
    "\n",
    "                        # Draw label\n",
    "                        cv2.putText(drawn_image, str(drawn_index), (x + offset_x, y + offset_y),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "                    drawn_index += 1\n",
    "\n",
    "                # Save the processed image\n",
    "                output_image_path = os.path.join(output_emotion_path, filename)\n",
    "                cv2.imwrite(output_image_path, drawn_image)\n",
    "                # print(f\"Saved processed image: {output_image_path}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"No face detected in {filename} from {emotion} folder.\")\n",
    "\n",
    "print(\"\\nAll emotion folders processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa0865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
